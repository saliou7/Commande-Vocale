{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le module librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une fonction pour lire un fichier audio\n",
    "def read_audio_file(file):\n",
    "    # Ouvrir le fichier validation_liste en mode lecture\n",
    "    with open(file, \"r\") as f:\n",
    "        # Créer une liste vide pour stocker les données audio\n",
    "        audio_data = []\n",
    "\n",
    "        # Créer une liste vide pour stocker les étiquettes\n",
    "        labels = []\n",
    "        \n",
    "        # Parcourir chaque ligne du fichier\n",
    "        for line in f:\n",
    "            # Supprimer le caractère de fin de ligne\n",
    "            line = line.strip()\n",
    "            # Charger le fichier audio avec librosa\n",
    "            y, sr = librosa.load(line, sr=16000)\n",
    "            # Ajouter le signal sonore et le taux d'échantillonnage à la liste\n",
    "            audio_data.append((y, sr))\n",
    "            # Ajouter l'étiquette à la liste\n",
    "            labels.append(line.split('/')[0])\n",
    "\n",
    "    return audio_data, labels\n",
    "\n",
    "# Charger le fichier audio\n",
    "audio_data, labels = read_audio_file(\"validation_list.txt\")\n",
    "\n",
    "# Créer un encodeur d'étiquettes\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Adapter l'encodeur aux étiquettes pour créer une correspondance entre les noms de classe et les entiers\n",
    "label_encoder.fit(labels)\n",
    "\n",
    "# Transformer les étiquettes en entiers\n",
    "labels = label_encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les MFCC pour les 50 premières trames (1 seconde)\n",
    "stride = 320 / 16000\n",
    "one_second_frames = int(1 / stride)\n",
    "\n",
    "def extract_mfcc_features(audio_data, sr=16000, n_mfcc=40, n_fft=1024, hop_length=320):\n",
    "    features = []\n",
    "    index_to_remove = []\n",
    "    for i, (audio, _) in enumerate(audio_data):\n",
    "        # Extraire les MFCC à partir du signal audio\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "        # Sélectionner les MFCC pour les 49 premières trames (1 seconde)\n",
    "        mfccs_one_second = mfccs[:, :one_second_frames]\n",
    "\n",
    "        if mfccs_one_second.shape[1] != one_second_frames:\n",
    "            index_to_remove.append(i)\n",
    "            continue\n",
    "        \n",
    "        mfccs = np.reshape(mfccs_one_second, (40 * one_second_frames,))\n",
    "\n",
    "        # Transposer les MFCC pour correspondre à l'orientation attendue (temps x caractéristiques)\n",
    "        features.append(mfccs.T)\n",
    "    return features, index_to_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_features, index_to_remove = extract_mfcc_features(audio_data)\n",
    "Y = np.delete(labels, index_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données test\n",
    "test_audio_data, test_labels = read_audio_file(\"testing_list.txt\")\n",
    "\n",
    "# Extraire les caractéristiques des signaux audio\n",
    "test_mfcc_features, test_index_to_remove = extract_mfcc_features(test_audio_data)\n",
    "test_mfcc_labels = np.delete(label_encoder.transform(test_labels), test_index_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =np.array(mfcc_features)\n",
    "\n",
    "# Créer un objet StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Utiliser la cross-validation pour évaluer le modèle\n",
    "# Créer un classifieur LogisticRegression multi-classe\n",
    "logistic_regression = LogisticRegression(max_iter=1000, multi_class=\"multinomial\")\n",
    "\n",
    "# Utiliser la cross-validation pour évaluer le modèle\n",
    "scores = cross_val_score(logistic_regression, X_train, mfcc_labels, cv=5)\n",
    "\n",
    "# Afficher les scores de la cross-validation\n",
    "print(\"Scores de la cross-validation : \", scores)\n",
    "\n",
    "# Entraîner le modèle\n",
    "logistic_regression.fit(X_train, mfcc_labels)\n",
    "\n",
    "# Prédire les étiquettes des données test\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(test_mfcc_labels, y_pred))\n",
    "\n",
    "# Afficher la précision\n",
    "print(\"Précision : \", accuracy_score(test_mfcc_labels, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la cross-validation :  [0.32342778 0.34830684 0.33586731 0.32135453 0.33195021]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.36      0.35        28\n",
      "           1       0.26      0.25      0.26        36\n",
      "           2       0.42      0.34      0.38        32\n",
      "           3       0.28      0.23      0.25        31\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.22      0.24      0.23        70\n",
      "           6       0.43      0.44      0.43        64\n",
      "           7       0.34      0.31      0.33        68\n",
      "           8       0.53      0.43      0.48        23\n",
      "           9       0.77      0.37      0.50        27\n",
      "          10       0.32      0.36      0.34        70\n",
      "          11       0.25      0.28      0.27        68\n",
      "          12       0.33      0.19      0.24        37\n",
      "          13       0.50      0.40      0.44        35\n",
      "          14       0.33      0.25      0.29        24\n",
      "          15       0.18      0.16      0.17        67\n",
      "          16       0.12      0.12      0.12        34\n",
      "          17       0.28      0.26      0.27        68\n",
      "          18       0.26      0.32      0.29        71\n",
      "          19       0.36      0.50      0.42        70\n",
      "          20       0.27      0.33      0.30        66\n",
      "          21       0.20      0.19      0.20        63\n",
      "          22       0.25      0.24      0.25        66\n",
      "          23       0.46      0.47      0.46        70\n",
      "          24       0.37      0.29      0.33        34\n",
      "          25       0.49      0.53      0.51        70\n",
      "          26       0.46      0.48      0.47        65\n",
      "          27       0.30      0.35      0.33        65\n",
      "          28       0.20      0.15      0.17        26\n",
      "          29       0.35      0.40      0.37        65\n",
      "          30       0.34      0.36      0.35        61\n",
      "          31       0.39      0.27      0.32        26\n",
      "          32       0.22      0.21      0.22        33\n",
      "          33       0.56      0.56      0.56        71\n",
      "          34       0.47      0.51      0.49        71\n",
      "\n",
      "    accuracy                           0.34      1809\n",
      "   macro avg       0.34      0.32      0.32      1809\n",
      "weighted avg       0.34      0.34      0.33      1809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array(mfcc_features)\n",
    "\n",
    "# Normalisation des caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Séparation des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# Création et entraînement du SVM linéaire\n",
    "clf = LogisticRegression(max_iter=1000)  # Par défaut, il gère la classification multiclasse\n",
    "\n",
    "#cross-validation\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Scores de la cross-validation : \", scores)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
